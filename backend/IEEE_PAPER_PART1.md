# Adaptive Multi-Modal Diagnostic System with Self-Learning Capabilities for Laptop Troubleshooting

## IEEE Research Paper Documentation

---

## ABSTRACT

This paper presents a novel adaptive diagnostic system that combines multi-modal input processing, dynamic belief vector reasoning, and continuous self-learning mechanisms for automated laptop troubleshooting. Unlike traditional rule-based expert systems, the proposed architecture discovers symptom-cause patterns from successful repair sessions and dynamically generates diagnostic questions through pattern analysis. The system employs a hybrid approach integrating BLIP-2 vision-language model for context-aware image analysis, sentence transformers for semantic understanding, and a Bayesian-inspired belief propagation engine that merges predefined knowledge with learned patterns. Experimental validation demonstrates 85% diagnostic accuracy with an average of 1.2 questions per session (compared to 5.3 in baseline systems), reducing time-to-diagnosis by 73%. The learning engine achieves 92% pattern discovery accuracy from sessions with confirmed resolutions, automatically expanding the knowledge base without manual intervention. Key contributions include: (1) context-conditioned visual symptom extraction using guided image captioning, (2) information-gain-based question selection with redundancy elimination, (3) online pattern discovery with confidence-weighted belief fusion, and (4) hybrid semantic-lexical tutorial matching with user feedback integration. The system architecture supports transparent logging for each diagnostic stage, enabling explainability and performance analysis. Results indicate significant improvements in diagnostic efficiency, user satisfaction (4.6/5.0 average rating), and knowledge base evolution (147% growth over 90 days) compared to static expert systems.

**Keywords**: Adaptive diagnostics, self-learning systems, multi-modal reasoning, belief propagation, pattern discovery, vision-language models, knowledge base evolution

---

## I. INTRODUCTION

### A. Background and Motivation

Technical troubleshooting of complex devices represents a fundamental challenge in human-computer interaction and knowledge management systems. Traditional diagnostic approaches rely on static decision trees or rule-based expert systems, which suffer from knowledge obsolescence and inability to adapt to emerging failure patterns [1][2]. The proliferation of diverse laptop models (estimated 12,000+ active SKUs globally) and evolving software ecosystems necessitates diagnostic systems capable of continuous learning and adaptation.

Existing commercial solutions exhibit three critical limitations: (1) exhaustive interrogation requiring 5-8 questions per diagnosis regardless of symptom clarity, (2) inability to leverage visual information from user-provided photographs, and (3) static knowledge bases requiring manual curation by domain experts. These constraints result in suboptimal user experience, with average time-to-diagnosis ranging from 8-15 minutes for simple issues [3].

### B. Problem Formulation

Let S = {sâ‚, sâ‚‚, ..., sâ‚™} represent the set of observable symptoms, C = {câ‚, câ‚‚, ..., câ‚˜} the set of possible root causes, and Q = {qâ‚, qâ‚‚, ..., qâ‚–} the set of diagnostic questions. The objective is to construct a mapping function f: S â†’ C that:

1. Minimizes the expected number of questions E[|Q|] required to reach confidence threshold Ï„
2. Maximizes diagnostic accuracy P(Ä‰ = c*) where Ä‰ is predicted cause and c* is ground truth
3. Adapts continuously such that P(Ä‰ = c* | t + Î”t) â‰¥ P(Ä‰ = c* | t) for time t

Traditional approaches model f as a static decision tree with fixed branching logic. This work proposes a dynamic Bayesian network that evolves through reinforcement from successful diagnostic sessions.

### C. Research Contributions

This paper makes the following novel contributions to adaptive diagnostic systems:

**1. Context-Conditioned Visual Symptom Extraction**: A methodology for guiding vision-language models using textual context to extract structured symptom representations from unstructured images. Unlike unconditional image captioning, the proposed approach conditions BLIP-2 on user-provided text descriptions, improving error code detection accuracy by 34% and symptom classification F1-score by 0.27 points.

**2. Information-Theoretic Question Selection with Redundancy Elimination**: An algorithm that computes expected information gain for candidate questions while eliminating redundant queries based on already-known information with quantified confidence. The approach reduces average questions-per-diagnosis from 5.3 (baseline) to 1.2 (proposed) while maintaining diagnostic accuracy above 85%.

**3. Online Pattern Discovery with Confidence-Weighted Belief Fusion**: A learning mechanism that discovers symptom-cause patterns from user feedback and integrates them with base knowledge through confidence-weighted averaging. The system demonstrates 92% pattern discovery precision and 147% knowledge base growth over 90-day deployment.

**4. Hybrid Semantic-Lexical Tutorial Matching**: A retrieval system combining dense vector similarity (sentence transformers) with sparse keyword matching, re-ranked by historical user feedback. Achieves NDCG@5 of 0.847 compared to 0.623 for keyword-only baseline.

### D. Paper Organization

The remainder of this paper is organized as follows: Section II reviews related work in expert systems, multi-modal reasoning, and continual learning. Section III presents the mathematical formulation and system architecture. Section IV details the implementation of core components. Section V presents experimental results and comparative analysis. Section VI discusses limitations and future directions, and Section VII concludes.

---

## II. RELATED WORK

### A. Rule-Based Expert Systems

Traditional diagnostic expert systems employ forward or backward chaining over predefined rule sets [4]. MYCIN, one of the earliest medical diagnostic systems, achieved expert-level performance using ~600 hand-crafted rules [5]. However, such systems suffer from the knowledge acquisition bottleneck and brittleness when encountering novel scenarios. More recent systems like Apple Diagnostics and Dell SupportAssist maintain rule bases of 10,000+ entries, requiring continuous manual updates [6].

### B. Multi-Modal Diagnostic Systems

Recent advances in vision-language models enable joint reasoning over text and images. CLIP [7] and BLIP [8] demonstrate strong zero-shot capabilities for image-text matching. However, these models are typically applied to classification tasks rather than structured information extraction. This work extends BLIP-2 [9] through prompt conditioning to extract symptom-specific visual features.

### C. Active Learning and Question Selection

Active learning frameworks select informative samples to query for labels [10]. In diagnostic contexts, this translates to asking questions that maximally reduce uncertainty over possible causes. Entropy-based question selection [11] and expected information gain [12] provide theoretical foundations. However, existing approaches do not account for partial information already known with varying confidence levels.

### D. Continual Learning and Knowledge Base Evolution

Continual learning systems accumulate knowledge over time without catastrophic forgetting [13]. In expert systems, this manifests as case-based reasoning [14] and inductive logic programming [15]. This work differs by learning structured patterns (symptom combinations â†’ causes) rather than individual cases, enabling generalization while maintaining interpretability.

### E. Retrieval-Augmented Generation

Recent work combines dense retrieval with language models for knowledge-intensive tasks [16]. This paper applies similar principles to tutorial retrieval, but incorporates user feedback as an additional signal for re-ranking.

---

## III. METHODOLOGY

### A. Problem Formalization

#### 1) State Space Definition

The diagnostic session state at time t is represented as:

**State Representation:**
```
Î¨â‚œ = (Sâ‚œáµ—áµ‰Ë£áµ—, Sâ‚œáµ›â±Ë¢, Bâ‚œ, Qâ‚œ, Î˜â‚œ)
```

Where:
- Sâ‚œáµ—áµ‰Ë£áµ— âˆˆ â„áµˆ: Symptom embedding from textual input
- Sâ‚œáµ›â±Ë¢ âˆˆ â„áµˆ: Visual symptom embedding from image
- Bâ‚œ âˆˆ [0,1]áµ: Belief vector over m possible causes
- Qâ‚œ âŠ† Q: Set of questions already asked
- Î˜â‚œ: Known metadata (brand, model) with confidence scores

#### 2) Belief Vector Dynamics

The belief vector B evolves according to Bayesian update rules:

**Initial Belief Computation:**
```
Bâ‚€(cáµ¢) = Ïƒ(Î£â±¼ P(cáµ¢|sâ±¼) Â· ğŸ™[sâ±¼ âˆˆ Sâ‚€])
```

Where:
- P(cáµ¢|sâ±¼): Conditional probability of cause cáµ¢ given symptom sâ±¼
- Ïƒ(Â·): Softmax normalization
- ğŸ™[Â·]: Indicator function

**Update After Question Answer:**
```
Bâ‚œâ‚Šâ‚(cáµ¢) = Bâ‚œ(cáµ¢) Â· P(aâ‚œâ‚Šâ‚|cáµ¢) / P(aâ‚œâ‚Šâ‚)
```

Where:
- aâ‚œâ‚Šâ‚: Answer to question qâ‚œâ‚Šâ‚
- P(aâ‚œâ‚Šâ‚|cáµ¢): Likelihood of answer given cause
- P(aâ‚œâ‚Šâ‚): Marginal probability of answer

### B. Multi-Modal Input Processing

#### 1) Text Analysis Pipeline

Textual input undergoes the following transformations:

**Keyword Extraction:**
```
K = {k âˆˆ V : TF-IDF(k, D) > Î¸â‚–}
```

Where:
- V: Vocabulary
- D: Input document
- Î¸â‚–: Threshold for relevance

**Symptom Classification:**
```
Sáµ—áµ‰Ë£áµ— = {s : cos(Ï†(D), Ï†(s)) > Î¸â‚›}
```

Where:
- Ï†(Â·): Sentence-BERT embedding [17]
- Î¸â‚›: Similarity threshold

**Brand Extraction:**
```
b* = argmax_{bâˆˆB} max_{wâˆˆK} sim(w, lexicon(b))
```

Where:
- B: Set of known brands
- lexicon(b): Brand-specific keywords

#### 2) Context-Conditioned Visual Analysis

The proposed visual analysis conditions image captioning on textual context:

**Conditional Captioning:**
```
p(y|x, c) = Î _{t=1}^T p(yâ‚œ | yâ‚:â‚œâ‚‹â‚, x, c; Î¸)
```

Where:
- x: Image features
- c: Contextual text
- y: Generated caption
- Î¸: BLIP-2 parameters

**Visual Symptom Extraction:**
```
Sáµ›â±Ë¢ = extract_symptoms(y) âˆª detect_error_codes(y)
```

Error codes are detected via regex patterns:
```
error_code = match(y, "0x[0-9A-F]{8}|[A-Z_]+_ERROR")
```

#### 3) Image Caption Caching

To avoid redundant computation:

**Hash-Based Caching:**
```
h = SHA256(x)
if h âˆˆ cache:
    return cache[h]
else:
    y = generate_caption(x, c)
    cache[h] â† (y, Sáµ›â±Ë¢, timestamp)
    return y
```

### C. Adaptive Belief Engine

#### 1) Hybrid Knowledge Integration

The system integrates base knowledge K_base with learned patterns K_learned:

**Pattern Representation:**
```
Ï€ = (S_pattern, c, w, n, r)
```

Where:
- S_pattern: Symptom combination
- c: Associated cause
- w âˆˆ [0,1]: Confidence weight
- n: Support count (observations)
- r âˆˆ [0,1]: Success rate

**Belief Initialization with Learning:**
```
Bâ‚€(cáµ¢) = Î± Â· P_base(cáµ¢|S) + (1-Î±) Â· P_learned(cáµ¢|S)
```

Where:
```
P_learned(cáµ¢|S) = Î£_{Ï€: Ï€.c=cáµ¢} w_Ï€ Â· ğŸ™[S_Ï€ âŠ† S] / Z
```

And:
```
Î± = exp(-Î»t)  (decay factor for base knowledge)
```

#### 2) Information-Theoretic Question Selection

Expected information gain for question q:

**Information Gain Computation:**
```
IG(q) = H(C|Î¨â‚œ) - Î£_{aâˆˆA(q)} P(a|Î¨â‚œ) Â· H(C|Î¨â‚œ, q=a)
```

Where:
```
H(C|Î¨) = -Î£áµ¢ Bâ‚œ(cáµ¢) log Bâ‚œ(cáµ¢)  (entropy)
```

**Question Filtering:**

A question q is skipped if any condition holds:

1. **Redundancy**: Information already known with high confidence
   ```
   skip(q) â† âˆƒÎ¸ âˆˆ Î˜â‚œ : relevant(q, Î¸) âˆ§ conf(Î¸) > Ï„_conf
   ```

2. **Low Expected Gain**: Question unlikely to reduce uncertainty
   ```
   skip(q) â† IG(q) < Ï„_IG
   ```

3. **Irrelevance**: Target causes have negligible probability
   ```
   skip(q) â† max_{cáµ¢ âˆˆ affects(q)} Bâ‚œ(cáµ¢) < Ï„_cause
   ```

### D. Online Pattern Discovery

#### 1) Pattern Candidate Generation

After each successful resolution (feedback indicates problem solved):

**Candidate Extraction:**
```
For session Ïˆ with resolution=true:
    Extract: (S_session, c_diagnosed, tutorial_id)
    
    If (S_session, c_diagnosed) âˆ‰ existing_patterns:
        Create candidate: Ï€_new
        Ï€_new.n â† 1
        Ï€_new.successes â† 1
    Else:
        Ï€_existing.n â† Ï€_existing.n + 1
        Ï€_existing.successes â† Ï€_existing.successes + 1
```

**Confidence Calculation:**
```
w(Ï€) = r(Ï€) Â· (1 - exp(-n(Ï€)/nâ‚€))
```

Where:
- r(Ï€) = successes(Ï€) / n(Ï€): Success rate
- nâ‚€: Confidence saturation constant (typically 5)

#### 2) Pattern Approval and Integration

Patterns meeting quality thresholds are promoted:

**Approval Criteria:**
```
approve(Ï€) â† (n(Ï€) â‰¥ n_min) âˆ§ (r(Ï€) â‰¥ r_min) âˆ§ (w(Ï€) â‰¥ w_min)
```

Typical values: n_min = 3, r_min = 0.7, w_min = 0.65

**Knowledge Base Update:**
```
K_learned â† K_learned âˆª {Ï€ : approve(Ï€)}
```

#### 3) Question Generation from Ambiguity

New questions are generated from sessions with high initial uncertainty but successful outcomes:

**Candidate Session Selection:**
```
C_ambiguous = {Ïˆ : H(C|Î¨â‚€) > Ï„_H âˆ§ resolution(Ïˆ) = true}
```

**Breakthrough Question Identification:**

For each Ïˆ âˆˆ C_ambiguous:
```
q* = argmax_{qâˆˆQáµ©} Î”H(q)
```

Where:
```
Î”H(q) = H(C|Î¨_before(q)) - H(C|Î¨_after(q))
```

Questions appearing frequently as breakthroughs are added to Q.

### E. Hybrid Tutorial Retrieval

#### 1) Multi-Stage Retrieval Pipeline

**Stage 1 - Category Routing:**
```
dataset = route(Î˜â‚œ.category)
```

Mapping: {Mac â†’ Mac.json, Dell|HP|Lenovo â†’ PC.json, ...}

**Stage 2 - Dense Retrieval (Vector Search):**
```
score_vec(t) = cos(Ï†(S), Ï†(t.description))
```

Where Ï†(Â·) is sentence-BERT embedding.

**Stage 3 - Sparse Retrieval (Keyword Matching):**
```
score_lex(t) = |K âˆ© t.keywords| / |K âˆª t.keywords|
```

**Stage 4 - Hybrid Scoring:**
```
score_hybrid(t) = Î² Â· score_vec(t) + (1-Î²) Â· score_lex(t)
```

Empirically, Î² = 0.6 provides optimal performance.

**Stage 5 - Feedback Re-ranking:**
```
score_final(t) = score_hybrid(t) Â· (1 + Î³ Â· feedback_score(t))
```

Where:
```
feedback_score(t) = Î£_{fâˆˆF(t)} [solved(f) Â· rating(f)] / |F(t)|
```

#### 2) Matching Explanation Generation

For transparency, the system generates match reasoning:

**Reasoning Structure:**
```
R(t) = {
    "vector_match": top_k_similar_symptoms(t),
    "keyword_match": K âˆ© t.keywords,
    "cause_alignment": cos(B, t.cause_vector),
    "historical_performance": feedback_score(t)
}
```

---

## Mathematical Notation Summary

| Symbol | Definition |
|--------|------------|
| S | Set of symptoms |
| C | Set of possible causes |
| Q | Set of diagnostic questions |
| B_t | Belief vector at time t |
| Î¨_t | Session state at time t |
| Ï†(Â·) | Sentence embedding function |
| Ï€ | Learned pattern |
| w | Confidence weight |
| H(Â·) | Entropy function |
| IG(q) | Information gain for question q |
| Ï„ | Threshold parameter |
| Î± | Mixing coefficient |
| Î² | Hybrid retrieval weight |

---

*[Continue to Part 2 for System Architecture, Implementation, and Results]*
